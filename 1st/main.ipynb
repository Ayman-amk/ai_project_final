{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 996
    },
    "id": "J-EfZ2czVTTY",
    "outputId": "80e03bca-0df2-49bb-8133-f0bbbb978deb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7p_rP3int_z2",
    "outputId": "0dc705e5-1b86-4631-ce2b-970a6198b65d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ayman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ayman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0420 - loss: 2.8635 - val_accuracy: 0.0943 - val_loss: 2.7460\n",
      "Epoch 2/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1562 - loss: 2.6729 - val_accuracy: 0.1509 - val_loss: 2.6824\n",
      "Epoch 3/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2242 - loss: 2.5394 - val_accuracy: 0.2264 - val_loss: 2.5457\n",
      "Epoch 4/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3044 - loss: 2.2744 - val_accuracy: 0.3962 - val_loss: 2.2748\n",
      "Epoch 5/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3856 - loss: 2.1935 - val_accuracy: 0.5094 - val_loss: 1.9494\n",
      "Epoch 6/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5268 - loss: 1.7314 - val_accuracy: 0.5660 - val_loss: 1.6206\n",
      "Epoch 7/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: 1.5557 - val_accuracy: 0.5472 - val_loss: 1.4334\n",
      "Epoch 8/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5643 - loss: 1.4462 - val_accuracy: 0.5849 - val_loss: 1.2188\n",
      "Epoch 9/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6977 - loss: 1.0745 - val_accuracy: 0.7547 - val_loss: 0.9537\n",
      "Epoch 10/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6453 - loss: 0.9890 - val_accuracy: 0.7925 - val_loss: 0.8015\n",
      "Epoch 11/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.8904 - val_accuracy: 0.8113 - val_loss: 0.6102\n",
      "Epoch 12/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.8105 - val_accuracy: 0.8491 - val_loss: 0.5236\n",
      "Epoch 13/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7108 - loss: 0.7771 - val_accuracy: 0.8491 - val_loss: 0.4762\n",
      "Epoch 14/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.5657 - val_accuracy: 0.8302 - val_loss: 0.4218\n",
      "Epoch 15/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.5779 - val_accuracy: 0.8491 - val_loss: 0.3813\n",
      "Epoch 16/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.4890 - val_accuracy: 0.8113 - val_loss: 0.4006\n",
      "Epoch 17/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8213 - loss: 0.5916 - val_accuracy: 0.8302 - val_loss: 0.3870\n",
      "Epoch 18/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.4086 - val_accuracy: 0.8302 - val_loss: 0.3349\n",
      "Epoch 19/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.3584 - val_accuracy: 0.8302 - val_loss: 0.3706\n",
      "Epoch 20/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3678 - val_accuracy: 0.8679 - val_loss: 0.2816\n",
      "Epoch 21/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2635 - val_accuracy: 0.8302 - val_loss: 0.3549\n",
      "Epoch 22/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.4087 - val_accuracy: 0.8302 - val_loss: 0.2996\n",
      "Epoch 23/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2901 - val_accuracy: 0.8302 - val_loss: 0.2831\n",
      "Epoch 24/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.3143 - val_accuracy: 0.8491 - val_loss: 0.2616\n",
      "Epoch 25/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2699 - val_accuracy: 0.8679 - val_loss: 0.2334\n",
      "Epoch 26/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.2546 - val_accuracy: 0.8679 - val_loss: 0.2770\n",
      "Epoch 27/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8737 - loss: 0.3301 - val_accuracy: 0.8302 - val_loss: 0.3000\n",
      "Epoch 28/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2670 - val_accuracy: 0.8491 - val_loss: 0.2857\n",
      "Epoch 29/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2545 - val_accuracy: 0.8491 - val_loss: 0.2817\n",
      "Epoch 30/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.2440 - val_accuracy: 0.8491 - val_loss: 0.3362\n",
      "Epoch 31/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.2450 - val_accuracy: 0.8491 - val_loss: 0.2567\n",
      "Epoch 32/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9131 - loss: 0.2138 - val_accuracy: 0.8491 - val_loss: 0.2593\n",
      "Epoch 33/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9194 - loss: 0.1973 - val_accuracy: 0.8302 - val_loss: 0.2983\n",
      "Epoch 34/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 0.1716 - val_accuracy: 0.8302 - val_loss: 0.3233\n",
      "Epoch 35/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8993 - loss: 0.2506 - val_accuracy: 0.8868 - val_loss: 0.2749\n",
      "Epoch 36/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.1952 - val_accuracy: 0.8491 - val_loss: 0.3271\n",
      "Epoch 37/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2155 - val_accuracy: 0.8491 - val_loss: 0.2666\n",
      "Epoch 38/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.2681 - val_accuracy: 0.8491 - val_loss: 0.2877\n",
      "Epoch 39/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9307 - loss: 0.1913 - val_accuracy: 0.8302 - val_loss: 0.2901\n",
      "Epoch 40/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9368 - loss: 0.2174 - val_accuracy: 0.8302 - val_loss: 0.2561\n",
      "Epoch 41/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.1784 - val_accuracy: 0.8679 - val_loss: 0.2435\n",
      "Epoch 42/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.3209 - val_accuracy: 0.8491 - val_loss: 0.2442\n",
      "Epoch 43/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9205 - loss: 0.1895 - val_accuracy: 0.8679 - val_loss: 0.2148\n",
      "Epoch 44/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.2016 - val_accuracy: 0.8302 - val_loss: 0.2865\n",
      "Epoch 45/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.1703 - val_accuracy: 0.8491 - val_loss: 0.2461\n",
      "Epoch 46/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.1956 - val_accuracy: 0.8679 - val_loss: 0.2259\n",
      "Epoch 47/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3028 - val_accuracy: 0.8302 - val_loss: 0.2836\n",
      "Epoch 48/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1512 - val_accuracy: 0.8491 - val_loss: 0.2365\n",
      "Epoch 49/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1371 - val_accuracy: 0.8491 - val_loss: 0.2629\n",
      "Epoch 50/50\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.2590 - val_accuracy: 0.8679 - val_loss: 0.2195\n",
      "Training Done!!!\n",
      "Bot is running...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "intents = json.loads(open('data.json').read())\n",
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignoreLetters = ['?', '!', '.', ',']\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        wordList = nltk.word_tokenize(pattern)\n",
    "        words.extend(wordList)\n",
    "        documents.append((wordList, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "words = [lemmatizer.lemmatize(word) for word in words if word not in ignoreLetters]\n",
    "words = sorted(set(words))\n",
    "\n",
    "classes = sorted(set(classes))\n",
    "\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))\n",
    "\n",
    "training = []\n",
    "outputEmpty = [0] * len(classes)\n",
    "\n",
    "for document in documents:\n",
    "    bag = []\n",
    "    wordPatterns = document[0]\n",
    "    wordPatterns = [lemmatizer.lemmatize(word.lower()) for word in wordPatterns]\n",
    "    for word in words:\n",
    "        bag.append(1) if word in wordPatterns else bag.append(0)\n",
    "\n",
    "    outputRow = list(outputEmpty)\n",
    "    outputRow[classes.index(document[1])] = 1\n",
    "    training.append(bag + outputRow)\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "trainX = training[:, :len(words)]\n",
    "trainY = training[:, len(words):]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, input_shape=(len(trainX[0]),), activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(len(trainY[0]), activation='softmax'))\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(trainX, trainY, test_size=0.2, random_state=42)\n",
    "history = model.fit(train_X, train_Y, validation_data=(val_X, val_Y), epochs=50, batch_size=5, verbose=1)\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "model.save('chatbot_model.keras')\n",
    "print('Training Done!!!')\n",
    "\n",
    "model = load_model('chatbot_model.keras')\n",
    "\n",
    "\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "model = load_model('chatbot_model.keras')\n",
    "\n",
    "def clean_up_sentnce(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    sentence_word = clean_up_sentnce(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for w in sentence_word:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence):\n",
    "    bow = bag_of_words(sentence)\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def get_reponse(intents_list, intents_json):\n",
    "    tag = intents_list[0]['intent']\n",
    "    print(tag)\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "print(\"Bot is running...\")\n",
    "\n",
    "# while True:\n",
    "#     message = input(\"\")\n",
    "#     ints = predict_class(message)\n",
    "#     res = get_reponse(ints, intents)\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words in the dataset: 179\n"
     ]
    }
   ],
   "source": [
    "total_unique_words = len(words)\n",
    "print(\"Total number of unique words in the dataset:\", total_unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m23,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)             │         \u001b[38;5;34m1,105\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,804</span> (253.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,804\u001b[0m (253.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,401</span> (126.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,401\u001b[0m (126.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,403</span> (126.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m32,403\u001b[0m (126.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-OZB9G9FVZGJ",
    "outputId": "ad457ca0-74b5-4557-c95b-060ea3126469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_true_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_X)\n\u001b[0;32m      2\u001b[0m val_predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(val_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(val_true_classes, val_predicted_classes)\n\u001b[0;32m      5\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m [intent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m intent \u001b[38;5;129;01min\u001b[39;00m intents[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintents\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# precision, recall, f1 score\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_true_classes' is not defined"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(val_X)\n",
    "val_predicted_classes = np.argmax(val_predictions, axis=1)\n",
    "conf_matrix = confusion_matrix(val_true_classes, val_predicted_classes)\n",
    "\n",
    "unique_labels = [intent['tag'] for intent in intents['intents']]\n",
    "\n",
    "# precision, recall, f1 score\n",
    "precision = precision_score(val_true_classes, val_predicted_classes, average='weighted')\n",
    "recall = recall_score(val_true_classes, val_predicted_classes, average='weighted')\n",
    "f1 = f1_score(val_true_classes, val_predicted_classes, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(val_X)\n",
    "val_predicted_classes = np.argmax(val_predictions, axis=1)\n",
    "val_true_classes = np.argmax(val_Y, axis=1)\n",
    "\n",
    "# training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "\n",
    "# training  validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
